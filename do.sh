NNODES=${NNODES:=$ARNOLD_WORKER_NUM}
NPROC_PER_NODE=${NPROC_PER_NODE:=$ARNOLD_WORKER_GPU}
NPROC_PER_NODE=${NPROC_PER_NODE:=$ARNOLD_WORKER_GPU_PER_NODE}
NODE_RANK=${NODE_RANK:=$ARNOLD_ID}
MASTER_ADDR=${MASTER_ADDR:=$ARNOLD_WORKER_0_HOST}
MASTER_ADDR=${MASTER_ADDR:=$ARNOLD_EXECUTOR_0_HOST}
MASTER_PORT=${MASTER_PORT:=$(echo "$ARNOLD_WORKER_0_PORT" | cut -d "," -f 1)}
MASTER_PORT=${MASTER_PORT:=$(echo "$ARNOLD_EXECUTOR_0_PORT" | cut -d "," -f 1)}



DISTRIBUTED_ARGS=(
    --nproc_per_node $NPROC_PER_NODE
    --nnodes $NNODES
    --node_rank $NODE_RANK
    --master_addr $MASTER_ADDR
    --master_port $MASTER_PORT
)

torchrun ${DISTRIBUTED_ARGS[@]} test.py